%\mychapter{7}{Discussion}
\section{Discussion and future direction}
In this section, first, we explain our observations based on experimental results with synthetic data.  Finally, we suggest possible future directions of addressing some short comings of our approach.


\subsection{Interpretation of our results}
Analyzing synthetic data using noisy previous time data captures the animals position around the simulated circular track 
while using diffusion maps. We regard this observation as a potentially exciting area for future investigation since noisy 
previous time data contains less information compared to using clean firing rate data. Even though we are using  synthetic data, these preliminary results show that pre-processing spike times using the previous time should be explored in future analyses of real-world spike train data from the CA1 region of the rat hippocampus. 

\subsection{Future directions}
First, at the beginning of the experiment, there are no recorded spike times.
However, we require that there is atleast one spike before a given brain state, in order to have the previous time function defined for all time. This raises a problem on how to address the boundary condition at the beginning
of the experiment. As it stands, we have addressed this problem by first running the experiment once to obtain the mean of the sampled previous time data, and afterwords, we insert a spike before the beginning of the experiment based on the computed previous time average, and then use that to simulate new  previous time data. We think that this is not the best approach for instance in the case where the mean of underlying distribution is not defined. In addition, computing the previous time vectors twice increases the computational complexity of our algorithm. We plan to find another way of addressing the boundary condition for the previous time vectors. For example, we plan to insert a spike before the beginning of the experiment based on samples drawn from a correctly estimated underlying model of the data.\\

Second, we currently do not have a measure of error for analysing the  effectiveness of our approach. 
We tried using the Shannon mutual information but found that  high  mutual information may be to due space noise, such as the animals head directions while running along the track which opens a variety of possible interpretations of the data.  We plan to use the Fisher information as a goodness of measure in future work. We think that the Fisher information is a likely a good measure of error, since it imposes a continuity assumption on the underlying model and is highest when then the variance of the estimated model parameter is very small. This could  yield a more reliable estimate of the animal's position along the simulated circular track. \\

We plan  to make harder simulations which mimic the real- world data we have.  For instance, we plan to  add additive and poisson noise to our simulated firing rate data.  In addition,  we plan to simulate  models in which each  neuron has 2 place fields. We hope that harder simulations and a good measure of error could guide us in the analysis of our real-world spike train data.\\

Finally, we plan to look at other types of distance measures for quantifying neural response variability such as variants of the kendal tau distance  or a weighted combination of some existing distances instead of the $l_1$ distance.\\

An improved approach such as the one we envision and outline here  may lead to new theories of mathematical neuroscience for analysing spike train data from animal hippocampuses.















%Our first step was to determine what dimensionality reduction algorithms to use.
%We decided to use Laplacian eigmaps \cite{belkin2003laplacian} and Diffusion Maps \cite{coifman2006} which are both non-linear dimensionality reduction algorithms.
%why?----to be addressed later.
%Initially, we smoothed the spike data using an exponential kernel defined by
%
%\[
%  K_{\tau}(t) =
%  \begin{cases}
%                 \frac{1}{\tau} \exp(-\frac{t}{\tau}) & \text{if $t > 0$} \\
%                  0 & \text{elsewhere} 
%  \end{cases}
%\]
%
%\subsection{Observations}
%We found that using Laplacian eigen maps to get an embedding based on the firing rate tried to
%recovered the position of the rat but could not reflect any variations along the path
%e.g the animal could have looked away from the track or run in a ragged fashion around the track.\\
%
%We also found that whenever there were gaps between the receptive fields (cases with no spikes),Laplacian Eigen Maps (LAM) performed poorly.
%This is because the nearest neighbor graph (based on the Euclidean distance used in (LAM) yields several connected components (i.e, the graph is disconnected).
%Since the eigen value decomposition step  in LAM is only applied on the largest connected
%component of the graph, the eigen vectors output by LAM are shorter than the total number of original data points (spike times). Thus the embedding provided by LAM is in accurate in some
%instances due to the "coverage" problem.\\
%
%Diffusion Maps (DM) algorithm tends to run out of memory in case of large instances
%so we were unable to compare the performance of both LAM and DM when using the firing rate.
%This is not true: First redo the analysis on sonet since you need to show that
%previous/next time is an improvement over the traditional firing rate.
%
%\subsection{Remedy for the coverage problem}
%Inspired by David Redish's idea, we decided to create previous and next time vectors which
%give us information even when there is no spike.
%This is the direction which seems promising at the moment since it tends to over come
%the problem of coverage. what is the coverage problem? (see reference on tunning curves).
%We then used the exponential kernel as our metric on the previous and next time data
%to generate a distance metric which is the main input in Diffusion Maps algorithm.
%
%
%
%
